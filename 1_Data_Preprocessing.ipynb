{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QeOt6jCkxG3A"
   },
   "outputs": [],
   "source": [
    "# Read In Data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "DataFrame = pd.read_csv('1_Customer_Data.csv')\n",
    "print(DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4ivDFOUVxfrO"
   },
   "outputs": [],
   "source": [
    "#8.1 Data Cleaning\n",
    "#Correlation\n",
    "\n",
    "DataFrame.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qAyigZI9xuyf"
   },
   "outputs": [],
   "source": [
    "#8.1 Data Cleaning\n",
    "#Duplication\n",
    "\n",
    "DataFrame.duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SGiBFIZrx4FI"
   },
   "outputs": [],
   "source": [
    "#8.2 Data Shuffling\n",
    "\n",
    "DataFrame.sample(frac=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mlXy9oy1yG7s"
   },
   "outputs": [],
   "source": [
    "#8.3 Data Imputation\n",
    "DataFrame.isna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "IDyIPur0yHEp",
    "outputId": "c8e81309-ed51-430b-c703-bd48fab100eb"
   },
   "outputs": [],
   "source": [
    "# 8.4 Data binning\n",
    "\n",
    "#Tree-based models can use label encodings using\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# creating initial dataframe\n",
    "bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
    "bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "bridge_df['Bridge_Types_Cat'] = labelencoder.fit_transform(bridge_df['Bridge_Types'])\n",
    "bridge_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-tree-based-models can use one-hot-encodings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# creating initial dataframe\n",
    "bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
    "bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "bridge_df['Bridge_Types_Cat'] = labelencoder.fit_transform(bridge_df['Bridge_Types'])\n",
    "bridge_df\n",
    "\n",
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(bridge_df[['Bridge_Types_Cat']]).toarray())\n",
    "\n",
    "# merge with main df bridge_df on key values\n",
    "bridge_df = bridge_df.join(enc_df)\n",
    "bridge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Non-tree-based-models can use one-hot-encodings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# creating initial dataframe\n",
    "bridge_types = ('Arch','Beam','Truss','Cantilever','Tied Arch','Suspension','Cable')\n",
    "bridge_df = pd.DataFrame(bridge_types, columns=['Bridge_Types'])\n",
    "\n",
    "# creating instance of labelencoder\n",
    "labelencoder = LabelEncoder()\n",
    "# Assigning numerical values and storing in another column\n",
    "bridge_df['Bridge_Types_Cat'] = labelencoder.fit_transform(bridge_df['Bridge_Types'])\n",
    "bridge_df\n",
    "\n",
    "# creating instance of one-hot-encoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# passing bridge-types-cat column (label encoded values of bridge_types)\n",
    "enc_df = pd.DataFrame(enc.fit_transform(bridge_df[['Bridge_Types_Cat']]).toarray())\n",
    "\n",
    "# merge with main df bridge_df on key values\n",
    "bridge_df = bridge_df.join(enc_df, lsuffix='_left', rsuffix='_right')\n",
    "bridge_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FNLWI63Qy5NH"
   },
   "outputs": [],
   "source": [
    "#8.5 Feature Scaling\n",
    "\n",
    "#Standardisation\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "iris = datasets.load_iris()  # loads the iris dataset\n",
    "\n",
    "scale= StandardScaler()\n",
    "\n",
    "# separate the independent and dependent variables\n",
    "X_data = iris.data\n",
    "target = iris.target\n",
    "\n",
    "# standardization of dependent variables\n",
    "scaled_data = scale.fit_transform(X_data)\n",
    "print(scaled_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4DI93DrYzPbL"
   },
   "outputs": [],
   "source": [
    "# Normalization\n",
    "\n",
    " # example of a normalization\n",
    "from numpy import asarray\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# define data\n",
    "data = asarray([[100, 0.001],\n",
    " [8, 0.05],\n",
    " [50, 0.005],\n",
    " [88, 0.07],\n",
    " [4, 0.1]])\n",
    "print(data)\n",
    "# define min max scaler\n",
    "scaler = MinMaxScaler()\n",
    "# transform data\n",
    "scaled = scaler.fit_transform(data)\n",
    "print(scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qBcEpgQ1zbXb"
   },
   "outputs": [],
   "source": [
    "# Gaussian Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WpkYW1p5zjh0"
   },
   "outputs": [],
   "source": [
    "#8.6 Train and Test split\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=111)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pu5S0NRqztGo"
   },
   "outputs": [],
   "source": [
    "#8.7 Cross validation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d0YUnlnvzuxY"
   },
   "outputs": [],
   "source": [
    "#Hold-out CV\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.25,\n",
    "                                                    random_state=111)\n",
    "\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jo_LaB8fzyRW"
   },
   "outputs": [],
   "source": [
    "#k-fold CV\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "k_folds = KFold(n_splits = 5)\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = k_folds)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uAt5VOwz6Em"
   },
   "outputs": [],
   "source": [
    "#Leave-one-out CV (LOOCV)\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import LeaveOneOut, cross_val_score\n",
    "\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "scores = cross_val_score(clf, X, y, cv = loo)\n",
    "\n",
    "print(\"Cross Validation Scores: \", scores)\n",
    "print(\"Average CV Score: \", scores.mean())\n",
    "print(\"Number of CV Scores used in Average: \", len(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
